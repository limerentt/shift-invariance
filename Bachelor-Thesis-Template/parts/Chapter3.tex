\section{Исследование и построение решения задачи}
\label{sec:Chapter3} \index{Chapter3}

Требуется разбить большую задачу, описанную в постановке, на более мелкие
подзадачи. Процесс декомпозиции следует продолжать до тех пор, пока подзадачи
не станут достаточно простыми для решения непосредственно. Это может быть
достигнуто, например, путем проведения эксперимента, доказательства теоремы
или поиска готового решения.

\subsection{Инвариантность к сдвигу в CNN-классификаторах}
\label{sec:invariance}

Сверточные нейронные сети (CNN) в теории должны обладать определенной степенью инвариантности к позиционным сдвигам входных данных. Это свойство изначально заложено в их архитектуру через механизм разделения весов и локальные рецептивные поля \cite{LeCun1998}. Однако, как показывают многочисленные исследования последних лет, современные CNN демонстрируют ограниченную инвариантность к сдвигам.

\subsubsection{Теоретические основы и эмпирические исследования}
\label{sec:invariance:theory}

Проблема инвариантности в CNN может быть систематически исследована через призму классической теории обработки сигналов. Azulay and Weiss \cite{Azulay2018} показали, что отсутствие антиалиасинговых фильтров перед операциями субдискретизации приводит к высокочастотному шуму в представлениях признаков, что делает модель чувствительной к малым сдвигам входных данных.

Zhang \cite{Zhang2019} идентифицировал операции даунсэмплинга (в частности, max-pooling и свертку с шагом больше 1) как основной источник нарушения инвариантности к сдвигам. В этой работе было показано, что субпиксельные сдвиги входных изображений могут приводить к значительным изменениям в активациях нейронов и, как следствие, к нестабильности выходных предсказаний модели.

Исследования показывают, что более глубокие сети, такие как ResNet \cite{He2016}, как правило, более инвариантны к сдвигам по сравнению с менее глубокими архитектурами, такими как AlexNet или VGG \cite{Simonyan2014}. Также наблюдается влияние типа пулинга на инвариантность: average-pooling обеспечивает лучшую инвариантность к сдвигам по сравнению с max-pooling.

\subsection{Методы анти-алиасинга в нейронных сетях}
\label{sec:antialias}

\subsubsection{Методы улучшения инвариантности: BlurPool и адаптивные подходы}
\label{sec:antialias:blurpool_and_adaptive}

После идентификации алиасинга как основной причины нарушения инвариантности к сдвигам в CNN, исследователи предложили ряд методов для решения этой проблемы.

\subsubsection{Низкочастотная фильтрация и BlurPool}
\label{sec:antialias:blurpool}

Наиболее прямолинейным подходом к борьбе с алиасингом является применение низкочастотной фильтрации перед операциями субдискретизации. Этот подход был впервые систематически применен к CNN в работе Zhang \cite{Zhang2019}, где был предложен метод BlurPool (Blur-then-downsampling).

В BlurPool операции max-pooling и свертки с шагом больше 1 модифицируются таким образом, что перед непосредственной субдискретизацией применяется размытие с использованием фиксированного низкочастотного фильтра. Авторы исследовали различные типы фильтров, включая простое усреднение (box filter), треугольный фильтр (binomial filter) и фильтр Гаусса, и показали, что даже простейшие из них значительно улучшают инвариантность сети к сдвигам.

Математически модификация стандартных операций может быть представлена следующим образом:

Для MaxPool с ядром $k$ и шагом $s$:
\begin{equation}
\text{MaxPool}_{k,s} = \text{Subsample}_{s} \circ \text{Max}_{k,1} \longrightarrow \text{Subsample}_{s} \circ \text{Blur}_{g} \circ \text{Max}_{k,1}
\end{equation}

Для свертки с шагом $s$:
\begin{equation}
\text{Conv}_{k,s} \longrightarrow \text{BlurPool}_{m,s} \circ \text{ReLU} \circ \text{Conv}_{k,1}
\end{equation}

где $g$ — низкочастотный фильтр размером $m \times m$, а символ $\circ$ обозначает композицию операций.

Важнейшие свойства низкочастотного фильтра:
\begin{itemize}
    \item Фильтр должен иметь нормированные веса: $\sum g_{ij} = 1$
    \item Бóльшие размеры фильтра (5×5, 7×7) обеспечивают лучшую инвариантность, но требуют больше вычислений
    \item Наиболее эффективными показали себя биномиальные фильтры, соответствующие строкам треугольника Паскаля (например, [1,2,1], [1,4,6,4,1])
\end{itemize}

\subsubsection{Полифазные методы и их применение в CNN}
\label{sec:antialias:tips_and_applications}

Более продвинутый подход к решению проблемы инвариантности предложен в работе Chaman and Dokmanić \cite{Chaman2021} — Translation Invariant Polyphase Sampling (TIPS). В отличие от BlurPool, который применяет фиксированный низкочастотный фильтр, TIPS использует полифазное разложение сигнала для явного моделирования и компенсации эффектов субдискретизации.

Метод TIPS опирается на теорию обработки сигналов и вводит количественную метрику для измерения проблемы — Maximum-Sampling Bias (MSB):

\begin{multline}
  \text{MSB} = \frac{1}{N}\sum_{n=1}^{N}\left(\max_{(i,j)\in\Omega_s}X_{n,i,j} - \mu_{\Omega_s}(X_n)\right),
\end{multline}

где $\Omega_s$ — окно с шагом $s$, а $\mu_{\Omega_s}(X_n)$ — среднее значение активаций $X_n$ по окну $\Omega_s$. Данная метрика измеряет склонность пулинга выбирать максимальные значения внутри окна, что экспериментально коррелирует с ухудшением инвариантности к сдвигам.

\subsection{Специфические проблемы инвариантности в детекторах объектов}
\label{sec:detectors}

Детекция объектов представляет собой более сложную задачу по сравнению с классификацией изображений, поскольку требует не только определения класса объекта, но и точной локализации его положения на изображении. Это делает проблему инвариантности к сдвигам особенно критичной для детекторов объектов.

\subsubsection{Архитектуры современных детекторов и влияние алиасинга}
\label{sec:detectors:architectures}

Современные детекторы объектов широко используют CNN в качестве основы для извлечения признаков и наследуют проблемы инвариантности к сдвигам, присущие этим архитектурам. Однако из-за необходимости точной локализации объектов, эти проблемы проявляются более ярко.

Moskvyak et al. \cite{Moskvyak2021} показали, что проблема особенно выражена в одностадийных детекторах, таких как YOLO. Это связано с тем, что эти детекторы используют фиксированную сетку для предсказания ограничивающих рамок, и небольшие изменения в представлениях признаков могут привести к тому, что объект будет ассоциирован с другой ячейкой сетки, вызывая значительное изменение в предсказании.

\newpage
