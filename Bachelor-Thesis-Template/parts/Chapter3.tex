\section{Теоретические основы инвариантности к сдвигам в CNN}
\label{sec:Chapter3} \index{Chapter3}

\subsection{Математическая формализация проблемы инвариантности}
\label{sec:math}

\subsubsection{Эквивариантность и инвариантность к сдвигам}

Проблема отсутствия инвариантности к сдвигам в современных сверточных нейронных сетях требует строгого математического формализма. Для изображения $X \in \mathbb{R}^{H \times W \times C}$ и функции нейронной сети $F: \mathbb{R}^{H \times W \times C} \to \mathbb{R}^{H' \times W' \times C'}$ (или $\mathbb{R}^K$ для классификации), определим оператор циклического сдвига:

\begin{equation}
\mathrm{Shift}_{\Delta h, \Delta w}(X)_{h,w,c} = X_{(h-\Delta h) \bmod H, (w-\Delta w) \bmod W, c}
\end{equation}

На основе этого определения можно формализовать два ключевых свойства:

\paragraph{Эквивариантность к сдвигам (shift-equivariance).} Функция $F$ эквивариантна к сдвигам, если сдвиг входа приводит к соответствующему сдвигу выхода:

\begin{equation}
\mathrm{Shift}_{\Delta h, \Delta w}(F(X)) = F(\mathrm{Shift}_{\Delta h, \Delta w}(X)), \quad \forall X, \forall \Delta h, \Delta w
\end{equation}

\paragraph{Инвариантность к сдвигам (shift-invariance).} Функция $F$ инвариантна к сдвигам, если сдвиг входа не влияет на выход:

\begin{equation}
F(X) = F(\mathrm{Shift}_{\Delta h, \Delta w}(X)), \quad \forall X, \forall \Delta h, \Delta w
\end{equation}

Теоретически, чистая операция свертки обладает идеальной эквивариантностью к сдвигам. Однако современные CNN используют операции субдискретизации (downsampling), которые эту эквивариантность нарушают.

\subsubsection{Нарушение эквивариантности при субдискретизации}

В архитектурах CNN используются три основных типа операций субдискретизации:
\begin{itemize}
    \item Свертка с шагом (strided convolution): $\text{Conv}_{k,s}$
    \item Максимальная выборка (max pooling): $\text{MaxPool}_{k,s}$
    \item Усредняющая выборка (average pooling): $\text{AvgPool}_{k,s}$
\end{itemize}

где $k$ — размер ядра, а $s$ — шаг (stride).

При использовании субдискретизации с шагом $s > 1$ эквивариантность сохраняется только для сдвигов, кратных $s$. Это свойство называется \textbf{periodic-$s$ equivariance}. Для более общего случая, если сеть содержит несколько слоев субдискретизации с общим эффективным шагом $N = \prod_i s_i$, то эквивариантность сохраняется только для сдвигов, кратных $N$ (periodic-$N$ equivariance).

Рассмотрим, почему субдискретизация нарушает эквивариантность. Пусть $\text{Subsample}_s$ — оператор выборки каждого $s$-го элемента:

\begin{equation}
\text{Subsample}_s(X)_{h,w,c} = X_{s \cdot h, s \cdot w, c}
\end{equation}

Для сдвига $\Delta$, не кратного $s$, мы получаем:

\begin{equation}
\text{Subsample}_s(\text{Shift}_{\Delta}(X)) \neq \text{Shift}_{\Delta/s}(\text{Subsample}_s(X))
\end{equation}

Это неравенство демонстрирует фундаментальное нарушение эквивариантности при субдискретизации.

\subsubsection{Алиасинг как источник проблемы}

С точки зрения теории обработки сигналов, нарушение эквивариантности связано с эффектом \textbf{алиасинга} (aliasing). При субдискретизации сигнала с шагом $s$ без предварительной низкочастотной фильтрации компоненты с частотой выше частоты Найквиста ($\pi/s$) неоднозначно отображаются на низкочастотный диапазон, что приводит к искажениям.

Математически, если $\hat{X}(\omega)$ — преобразование Фурье сигнала $X$, то субдискретизация с шагом $s$ приводит к следующему спектру:

\begin{equation}
\hat{Y}(\omega) = \frac{1}{s} \sum_{k=0}^{s-1} \hat{X}\left(\frac{\omega - 2\pi k}{s}\right)
\end{equation}

Этот спектр содержит копии (реплики) исходного спектра, смещенные на $2\pi k/s$ и масштабированные на $1/s$. Если исходный сигнал не ограничен по частоте (bandlimited) или недостаточно отфильтрован, эти реплики накладываются друг на друга, вызывая алиасинг.

В контексте CNN это означает, что малые сдвиги входного изображения могут приводить к непредсказуемым изменениям в активациях нейронов после слоев с субдискретизацией. Эти изменения затем распространяются через сеть, вызывая нестабильность выходных предсказаний.

Экспериментально установлено, что даже субпиксельные сдвиги (менее одного пикселя) могут привести к значительным изменениям в выходах современных CNN, что противоречит интуитивным ожиданиям о их инвариантности к сдвигам.

\subsection{Методы повышения инвариантности к сдвигам}
\label{sec:methods}

\subsubsection{BlurPool: антиалиасинг через низкочастотную фильтрацию}
\label{sec:methods:blurpool}

BlurPool реализует классический принцип обработки сигналов: перед субдискретизацией необходимо применить низкочастотный фильтр для устранения частот выше частоты Найквиста. Математически операция BlurPool с фильтром размера $m \times m$ и шагом субдискретизации $s$ определяется как:

\begin{equation}
\text{BlurPool}_{m,s}(x) = \text{Subsample}_{s}(\text{Blur}_{m}(x))
\end{equation}

где $\text{Blur}_{m}$ — операция свёртки с фиксированным низкочастотным фильтром, а $\text{Subsample}_{s}$ — операция выборки каждого $s$-го элемента.

В качестве фильтров используются биномиальные ядра, аппроксимирующие гауссово распределение:

\begin{itemize}
    \item \textbf{Triangle-3}: $K_3 = \frac{1}{16}[1, 2, 1]^T \cdot [1, 2, 1]$
    \item \textbf{Binomial-5}: $K_5 = \frac{1}{256}[1, 4, 6, 4, 1]^T \cdot [1, 4, 6, 4, 1]$
\end{itemize}

Модификация стандартных операций субдискретизации:

\begin{itemize}
    \item $\text{MaxPool}_{k,s} \rightarrow \text{Subsample}_{s} \circ \text{Blur}_{m} \circ \text{Max}_{k,1}$
    \item $\text{Conv}_{k,s} \rightarrow \text{Subsample}_{s} \circ \text{Blur}_{m} \circ \text{Conv}_{k,1}$
    \item $\text{AvgPool}_{k,s} \rightarrow \text{Subsample}_{s} \circ \text{Blur}_{m}$
\end{itemize}

Преимущество BlurPool заключается в его простоте и эффективности: метод вносит минимальные изменения в архитектуру, увеличивая вычислительную сложность менее чем на 1\%, при этом значительно повышая инвариантность к сдвигам.

\subsubsection{TIPS: полифазная декомпозиция для инвариантности}
\label{sec:methods:tips}

Translation Invariant Polyphase Sampling (TIPS) представляет более фундаментальный подход к обеспечению инвариантности, основанный на полифазной декомпозиции сигнала. Метод разбивает входной сигнал на $s^2$ фаз, соответствующих различным положениям относительно сетки субдискретизации, и комбинирует их с помощью обучаемых весов:

\begin{equation}
\text{TIPS}_s(x) = \sum_{i=0}^{s-1}\sum_{j=0}^{s-1} \tau_{is+j} \cdot \text{Subsample}_{s}(\text{Shift}_{(i,j)}(x))
\end{equation}

где $\text{Shift}_{(i,j)}$ — операция сдвига на $(i,j)$ пикселей, а $\tau_{is+j} \in [0,1]$ — обучаемые смешивающие коэффициенты для каждой фазы, получаемые с помощью небольшой shift-инвариантной функции.

В практической реализации TIPS для слоя с шагом $s$ создаются $s^2$ параллельных вычислительных путей, каждый обрабатывающий сдвинутую версию входного тензора. Результаты всех путей взвешенно объединяются с обучаемыми коэффициентами для формирования инвариантного представления.

TIPS обеспечивает теоретическую гарантию инвариантности к целочисленным сдвигам и высокую степень инвариантности к субпиксельным сдвигам. Вычислительная сложность метода выше, чем у BlurPool, но для небольших значений $s$ (обычно $s=2$) остается приемлемой.

\newpage
\section{Экспериментальная методология и модификации архитектур}
\label{sec:Chapter4} \index{Chapter4}

\subsection{Экспериментальные данные и их подготовка}
\label{sec:experimental_data}

\subsubsection{Используемые датасеты}
\label{sec:datasets}

Для комплексной оценки влияния методов повышения инвариантности к сдвигам на качество моделей используются следующие датасеты:

\begin{itemize}
    \item \textbf{CIFAR-10} — стандартный датасет для классификации изображений, содержащий 60 000 цветных изображений размером 32×32 пикселя в 10 классах (50 000 для обучения и 10 000 для тестирования).
    
    \item \textbf{ImageNet-mini} — уменьшенная версия ImageNet, содержащая 100 классов по 1300 изображений различного разрешения, адаптированная для более быстрых экспериментов.
    
    \item \textbf{Imagenette} — подмножество ImageNet с 10 легко распознаваемыми классами, позволяющее проводить быстрые итерации экспериментов с сохранением характеристик полного датасета.
    
    \item \textbf{COCO-sample} — выборка из датасета COCO (Common Objects in Context), содержащая аннотации для задачи детекции объектов. Используется для обучения и оценки моделей детекции.
\end{itemize}

\subsubsection{Подготовка тестовых данных с контролируемыми сдвигами}
\label{sec:data_preparation}

Для количественной оценки инвариантности к сдвигам разработан специальный протокол формирования тестовых данных:

\begin{enumerate}
    \item \textbf{Синтетические последовательности сдвигов}: 
    Из исходных изображений создаются последовательности с контролируемыми сдвигами от 0 до 8 пикселей с шагом 1 пиксель по горизонтали и вертикали. Для создания субпиксельных сдвигов используется билинейная интерполяция, обеспечивающая гладкое перемещение объектов. 
    
    \item \textbf{Комбинированные сцены для детекции}: 
    Для задач детекции объектов формируются композитные сцены, где на различные фоновые изображения накладываются объекты с контролируемыми положениями и масштабами. Это позволяет точно оценивать влияние сдвигов на качество детекции при известных истинных координатах объектов.
    
    \item \textbf{Аугментации тестового набора}:
    На основе исходных тестовых наборов (CIFAR-10 test, ImageNet-mini validation) создаются расширенные версии с применением только геометрических преобразований (сдвиги, повороты, масштабирование), сохраняющие исходные классы. Каждое исходное изображение порождает до 8 модифицированных версий с различными сдвигами.
\end{enumerate}

Для автоматизации этого процесса разработан специальный Python-скрипт (см. Приложение~\ref{appendix:data_generation}), который обеспечивает воспроизводимость экспериментов и контроль над точными параметрами преобразований.

\subsection{Адаптация методов для архитектур глубокого обучения}
\label{sec:architectures}

\subsubsection{Модификации классификационных моделей}
\label{sec:architectures:classification}

Для классификационных архитектур (VGG16, ResNet50) методы повышения инвариантности применяются к различным типам слоев с субдискретизацией:

\begin{itemize}
    \item В \textbf{VGG16} заменяются все max-pooling слои.
    \item В \textbf{ResNet50} модифицируются как свёртки с шагом 2 в ResNet-блоках, так и финальный average-pooling слой.
\end{itemize}

Существенно, что модификации могут быть применены к предобученным моделям без полного переобучения, заменяя только соответствующие слои и при необходимости выполняя тонкую настройку. Ключевые фрагменты кода реализации модифицированных классификационных моделей представлены в Приложении~\ref{appendix:classifiers_code}.

\subsubsection{Модификации архитектуры YOLOv5}
\label{sec:architectures:yolo}

Детектор объектов YOLOv5 имеет сложную архитектуру, состоящую из трёх основных компонентов:

\begin{itemize}
    \item \textbf{Backbone (CSPDarknet)} — извлекает иерархические признаки из изображения.
    \item \textbf{Neck (PANet)} — объединяет признаки разных масштабов через восходящие и нисходящие пути.
    \item \textbf{Head} — преобразует многоуровневые признаки в предсказания классов и ограничивающих рамок.
\end{itemize}

Операции субдискретизации присутствуют как в backbone (для последовательного уменьшения пространственного разрешения), так и в neck (для перехода между уровнями признаков). Модификации включают:

\begin{itemize}
    \item \textbf{YOLOv5-BlurPool}: замена всех сверток с шагом 2 на последовательность из свертки с шагом 1 и BlurPool операции.
    \item \textbf{YOLOv5-TIPS}: замена сверток с шагом 2 на TIPS-модули с соответствующим числом параллельных путей.
\end{itemize}

Особое внимание уделяется сохранению вычислительной эффективности, что критично для детекторов, работающих в режиме реального времени. Основные элементы реализации модификаций YOLOv5 представлены в Приложении~\ref{appendix:yolo_code}.

\subsection{Экспериментальная инфраструктура}
\label{sec:infrastructure}

\subsubsection{Программная реализация}
\label{sec:implementation}

Для проведения экспериментов разработана программная инфраструктура на языке Python с использованием фреймворка PyTorch. Ключевые компоненты включают:

\begin{itemize}
    \item \textbf{Модули с реализациями методов BlurPool и TIPS} (см. Приложение~\ref{appendix:antialiasing_code}), которые можно интегрировать в различные архитектуры нейронных сетей.
    
    \item \textbf{Модифицированные архитектуры классификаторов} (VGG16, ResNet50) с антиалиасинговыми компонентами (см. Приложение~\ref{appendix:classifiers_code}).
    
    \item \textbf{Модифицированные архитектуры YOLOv5} с компонентами BlurPool и TIPS (см. Приложение~\ref{appendix:yolo_code}).
    
    \item \textbf{Скрипты для оценки инвариантности} (см. Приложение~\ref{appendix:evaluation_code}), реализующие описанные в разделе~\ref{sec:evaluation} метрики.
\end{itemize}

Вся программная инфраструктура разработана с учетом требований масштабируемости и воспроизводимости экспериментов, что позволяет легко адаптировать её для различных архитектур нейронных сетей и задач компьютерного зрения.

\subsubsection{Аппаратное обеспечение}
\label{sec:hardware}

Эксперименты проводились на следующем оборудовании:
\begin{itemize}
    \item GPU NVIDIA GeForce RTX 3090 (24 ГБ VRAM)
    \item CPU Intel Core i9-10900K (10 ядер, 20 потоков)
    \item 64 ГБ оперативной памяти DDR4
\end{itemize}

Для обучения крупных моделей на полных датасетах дополнительно использовались вычислительные ресурсы Google Colab Pro с доступом к GPU NVIDIA Tesla V100.

\subsection{Методология оценки инвариантности}
\label{sec:evaluation}

\subsubsection{Метрики для классификационных моделей}
\label{sec:evaluation:classification}

Для всесторонней оценки инвариантности классификаторов используются следующие метрики:

\begin{itemize}
    \item \textbf{Top-1 Accuracy (Acc)}: базовая метрика точности классификации, доля правильно классифицированных изображений.
    
    \item \textbf{Consistency (Cons)}: вероятность одинакового предсказанного класса для исходного и сдвинутого изображения:
    \begin{equation}
    \text{Cons} = \mathbb{E}_{x, \delta} \left[ \mathbb{I} \left( \underset{c}{\text{argmax}} \, f(x)_c = \underset{c}{\text{argmax}} \, f(\mathcal{T}_\delta(x))_c \right) \right]
    \end{equation}
    
    \item \textbf{Stability (Stab)}: среднее косинусное сходство между выходными представлениями для исходного и сдвинутого изображения:
    \begin{equation}
    \text{Stab} = \mathbb{E}_{x, \delta} \left[ \frac{f(x) \cdot f(\mathcal{T}_\delta(x))}{\|f(x)\| \cdot \|f(\mathcal{T}_\delta(x))\|} \right]
    \end{equation}
\end{itemize}

Основные фрагменты кода для вычисления этих метрик представлены в Приложении~\ref{appendix:evaluation_code}.

\subsubsection{Метрики для детекторов объектов}
\label{sec:evaluation:detection}

Для детекторов объектов используются специализированные метрики:

\begin{itemize}
    \item \textbf{Mean Average Precision (mAP)}: стандартная метрика точности детекции, учитывающая как классификацию, так и локализацию объектов при различных порогах IoU.
    
    \item \textbf{IoU Stability (IS)}: стабильность пересечения над объединением предсказанных рамок при сдвигах:
    \begin{equation}
    \text{IS} = \mathbb{E}_{x, \delta, b} \left[ \text{IoU} \left( b, \mathcal{T}_{-\delta}(b_{\delta}) \right) \right]
    \end{equation}
    где $b$ — предсказанная рамка для исходного изображения, $b_{\delta}$ — рамка для сдвинутого изображения, а $\mathcal{T}_{-\delta}$ — обратный сдвиг для компенсации смещения изображения.
    
    \item \textbf{Center Drift (CD)}: среднее евклидово расстояние между центрами предсказанных рамок после компенсации сдвига:
    \begin{equation}
    \text{CD} = \mathbb{E}_{x, \delta, b} \left[ \| \text{center}(b) - \text{center}(\mathcal{T}_{-\delta}(b_{\delta})) \|_2 \right]
    \end{equation}
\end{itemize}

Основные алгоритмы оценки детекторов объектов также представлены в Приложении~\ref{appendix:evaluation_code}.

\subsubsection{Протокол тестирования}
\label{sec:evaluation:protocol}

Стандартизированный протокол тестирования включает:

\begin{enumerate}
    \item \textbf{Генерацию тестовых сдвигов}: для каждого тестового изображения создается набор сдвинутых версий с субпиксельной точностью (с шагом 1/8 пикселя) в диапазоне $[-1, 1]$ пикселя.
    
    \item \textbf{Предобработку изображений}: стандартное изменение размера до 224×224 пикселей для классификации и 640×640 для детекции, нормализация пикселей.
    
    \item \textbf{Оценку инвариантности}: для каждой пары (исходное изображение, сдвинутая версия) вычисляются соответствующие метрики инвариантности.
    
    \item \textbf{Агрегацию результатов}: метрики усредняются по всем изображениям и всем сдвигам для получения итоговых показателей.
\end{enumerate}

Этот подход обеспечивает объективное сравнение различных архитектур и методов с точки зрения их инвариантности к пространственным сдвигам входных данных. Ключевые элементы реализации протокола тестирования представлены в Приложении~\ref{appendix:evaluation_code}.

\newpage
