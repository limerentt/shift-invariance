\section{Исследование и построение решения задачи}
\label{sec:Chapter3} \index{Chapter3}

В данной главе описывается исследовательская часть работы, основанная на анализе литературы, представленном в предыдущей главе. Здесь рассматриваются методы улучшения инвариантности к сдвигам в современных нейронных сетях, математическая формализация проблемы и предлагаемые модификации архитектур.

\subsection{Математическая формализация проблемы инвариантности}
\label{sec:math}

На основе проведенного обзора литературы, представленного в предыдущей главе, можно формализовать проблему инвариантности к сдвигам в нейронных сетях. 

Для формального определения свойства инвариантности к сдвигам рассмотрим функцию $f: \mathbb{R}^{H \times W \times C} \rightarrow \mathbb{R}^K$, представляющую нейронную сеть, где $H$, $W$ и $C$ — высота, ширина и число каналов входного изображения, а $K$ — размерность выходного вектора.

Для операции сдвига $\mathcal{T}_{\Delta h, \Delta w}$, которая смещает изображение на $\Delta h$ пикселей по вертикали и $\Delta w$ пикселей по горизонтали, свойство инвариантности может быть записано как:

\begin{equation}
f(\mathcal{T}_{\Delta h, \Delta w}(x)) \approx f(x) \quad \forall x \in \mathbb{R}^{H \times W \times C}, \forall \Delta h, \Delta w \in \mathbb{R}
\end{equation}

где знак $\approx$ означает близость векторов в некоторой метрике, например, в косинусном сходстве или евклидовом расстоянии.

Для количественной оценки степени инвариантности к сдвигам будем использовать метрику стабильности предсказаний при субпиксельных сдвигах:

\begin{equation}
S(f) = \frac{1}{N}\sum_{i=1}^{N} \frac{1}{|\Delta|} \sum_{\delta \in \Delta} \text{sim}(f(x_i), f(\mathcal{T}_\delta(x_i)))
\end{equation}

где $N$ — количество тестовых изображений, $\Delta$ — набор малых сдвигов, а $\text{sim}$ — функция сходства (например, косинусное сходство).

\subsection{Модификации архитектур с анти-алиасингом}
\label{sec:architectures}

На основе проведенного обзора существующих методов борьбы с алиасингом (aliasing), в данной работе предлагаются модификации классических архитектур нейронных сетей для улучшения их инвариантности к сдвигам. Исследование фокусируется на двух основных подходах: BlurPool и TIPS, адаптируя их для различных типов сетей.

\subsubsection{Применение BlurPool в классификационных моделях}
\label{sec:architectures:blurpool_classification}

Для классификационных моделей VGG16 и ResNet50 были реализованы модификации с применением BlurPool. Модификация заключалась в замене всех операций даунсэмплинга (max-pooling и свертки с шагом) на их аналоги с предварительной низкочастотной фильтрацией.

Метод BlurPool, предложенный Zhang et al., вставляет низкочастотный фильтр перед операцией субдискретизации для предотвращения алиасинга. Формально это можно записать как:

$$\text{BlurPool}_{m,s} = \text{Subsample}_{s} \circ \text{Blur}_{m}$$

где $\text{Subsample}_{s}$ — операция субдискретизации с шагом $s$ (обычно 2), $\text{Blur}_{m}$ — операция свёртки с фиксированным низкочастотным фильтром размера $m \times m$, а $\circ$ обозначает композицию операций.

Для реализации BlurPool были использованы биномиальные фильтры различных размеров:
\begin{itemize}
    \item \textbf{Triangle-3}: [1, 2, 1] × [1, 2, 1]$^{T}$ / 16 — эквивалент билинейной интерполяции
    \item \textbf{Binomial-5}: [1, 4, 6, 4, 1] × [1, 4, 6, 4, 1]$^{T}$ / 256 — соответствует строкам треугольника Паскаля
\end{itemize}

Эти фильтры действуют как низкочастотные, снижая энергию высокочастотных компонентов сигнала перед субдискретизацией, что помогает минимизировать эффект алиасинга.

Модификация архитектур с BlurPool применяется следующим образом:

\begin{enumerate}
    \item \textbf{MaxPool} преобразуется в последовательность:
    $$\text{MaxPool}_{k,s} \to \text{Subsample}_{s} \circ \text{Blur}_{m} \circ \text{Max}_{k,1}$$
    где $\text{Max}_{k,1}$ — операция max-pooling с ядром $k$ и шагом 1.
    
    \item \textbf{Свертка с шагом} преобразуется в:
    $$\text{Conv}_{k,s} \to \text{BlurPool}_{m,s} \circ \text{ReLU} \circ \text{Conv}_{k,1}$$
    где $\text{Conv}_{k,1}$ — свертка с ядром $k$ и шагом 1.
    
    \item \textbf{AvgPool} просто заменяется на:
    $$\text{AvgPool}_{k,s} \to \text{BlurPool}_{m,s}$$
\end{enumerate}

В VGG16-bn были модифицированы все слои max-pooling, а в ResNet50 — все свертки с шагом 2. Важное преимущество метода BlurPool заключается в том, что модификация не требует переобучения весов down-sampling слоев и может быть применена к предобученным моделям с сохранением большей части их весов. Вычислительные затраты увеличиваются минимально (<1%), что делает данный подход практически применимым для широкого спектра задач.

\subsubsection{Реализация TIPS для повышения инвариантности}
\label{sec:architectures:tips}

Для продвинутого подхода к проблеме инвариантности был реализован метод TIPS (Translation Invariant Polyphase Sampling). В отличие от BlurPool, TIPS требует более существенных изменений в архитектуре сети.

Основная идея TIPS заключается в разделении сигнала на несколько фаз в зависимости от его положения относительно сетки субдискретизации. Математически это может быть представлено как:

\begin{equation}
\text{TIPS}(x) = \frac{1}{s^2}\sum_{i=0}^{s-1}\sum_{j=0}^{s-1} \text{Subsample}_{s}(\text{Shift}_{(i,j)}(x))
\end{equation}

где $s$ - коэффициент субдискретизации, а $\text{Shift}_{(i,j)}$ - операция сдвига на $(i,j)$ пикселей.

В данной реализации TIPS для слоя max-pooling с размером ядра $k$ и шагом $s$ создаются $s^2$ отдельных ветвей, каждая из которых обрабатывает сдвинутую версию входного тензора. Затем результаты всех ветвей объединяются для формирования инвариантного к сдвигам представления.

\subsection{Архитектура YOLOv5 и её модификации}
\label{sec:yolov5}

Особое внимание в данной работе уделяется улучшению инвариантности к сдвигам в детекторах объектов. В качестве базовой архитектуры выбран YOLOv5 - одностадийный детектор, демонстрирующий хороший баланс между скоростью и точностью.

\subsubsection{Структура YOLOv5 и места внедрения анти-алиасинга}
\label{sec:yolov5:structure}

Архитектура YOLOv5 состоит из трех основных компонентов:
\begin{itemize}
    \item Backbone (CSPDarknet) - извлекает признаки из изображения
    \item Neck (PANet) - объединяет признаки с разных уровней для улучшения мультимасштабной детекции
    \item Head - преобразует признаки в предсказания ограничивающих рамок и классов
\end{itemize}

Наши модификации затрагивают все операции даунсэмплинга в backbone и neck сети. В стандартной архитектуре YOLOv5 даунсэмплинг осуществляется с помощью сверток с шагом 2, которые являются источником алиасинга и, следовательно, нарушения инвариантности.

Мы реализовали две модификации архитектуры:
\begin{enumerate}
    \item YOLOv5-BlurPool: замена всех сверток с шагом 2 на последовательность из обычной свертки (с шагом 1) и блока BlurPool
    \item YOLOv5-TIPS: более радикальная модификация с заменой всех сверток с шагом 2 на TIPS-модули
\end{enumerate}

\subsubsection{Ожидаемые эффекты от модификаций}
\label{sec:yolov5:effects}

От внедрения методов анти-алиасинга в архитектуру YOLOv5 ожидаются следующие улучшения:
\begin{itemize}
    \item Повышение стабильности предсказаний при малых сдвигах входных изображений
    \item Уменьшение дрейфа центра ограничивающей рамки
    \item Более высокую стабильность IoU между предсказанными и истинными ограничивающими рамками
    \item Более равномерное распределение ошибок локализации
\end{itemize}

При этом модификации могут привести к некоторому увеличению вычислительной сложности и времени инференса, что является допустимой платой за повышение надежности модели.

\subsection{Методология оценки инвариантности}
\label{sec:evaluation}

Для количественной оценки эффективности предложенных модификаций разработана комплексная методология тестирования инвариантности к сдвигам, основанная на работе Zhang et al. "Making Convolutional Networks Shift-Invariant Again".

\subsubsection{Метрики инвариантности для классификационных моделей}
\label{sec:evaluation:classification}

Для классификационных моделей (VGG16, ResNet50) используются следующие метрики:

\begin{itemize}
    \item \textbf{Top-1 Accuracy (Acc)}: стандартная метрика точности классификации, показывающая долю правильно классифицированных изображений из тестового набора.
    
    \item \textbf{Consistency (Cons)}: ключевая метрика инвариантности, которая измеряет стабильность предсказаний при малых сдвигах входных данных. Вычисляется как вероятность того, что модель дает одинаковое предсказание (Top-1) для исходного и сдвинутого изображения:
    \begin{equation}
    \text{Cons} = \mathbb{E}_{x, \delta} [\mathbb{1}(\arg\max f(x) = \arg\max f(\mathcal{T}_\delta(x)))]
    \end{equation}
    где $\mathcal{T}_\delta$ обозначает оператор сдвига на вектор $\delta$, а $\mathbb{1}$ — индикаторная функция.
    
    \item \textbf{Expected Consistency (ExCons)}: расширение метрики Consistency, которое учитывает не только совпадение класса с наибольшей вероятностью, но и распределение вероятностей по всем классам:
    \begin{equation}
    \text{ExCons} = \mathbb{E}_{x, \delta} [\text{KL}(f(x) || f(\mathcal{T}_\delta(x)))]
    \end{equation}
    где $\text{KL}$ — дивергенция Кульбака-Лейблера.
    
    \item \textbf{Stability (Stab)}: измеряет среднее косинусное сходство между выходными представлениями для оригинального и сдвинутого изображений:
    \begin{equation}
    \text{Stab} = \mathbb{E}_{x, \delta} [\text{cos\_sim}(f(x), f(\mathcal{T}_\delta(x)))]
    \end{equation}
    где $\text{cos\_sim}$ — косинусное сходство между векторами.
\end{itemize}

\subsubsection{Метрики инвариантности для детекторов объектов}
\label{sec:evaluation:detection}

Для оценки инвариантности детекторов объектов (YOLOv5 и его модификаций) используются следующие метрики:

\begin{itemize}
    \item \textbf{mAP}: стандартная метрика для оценки точности детекции, измеряющая среднюю точность по всем классам при различных порогах IoU.
    
    \item \textbf{IoU Stability (IS)}: оценивает стабильность пересечения над объединением предсказанных ограничивающих рамок при сдвигах:
    \begin{equation}
    \text{IS} = \mathbb{E}_{x, \delta, b} [\text{IoU}(b, \mathcal{T}_{-\delta}(b_{\delta}))]
    \end{equation}
    где $b$ — ограничивающая рамка для исходного изображения, $b_{\delta}$ — соответствующая рамка для сдвинутого изображения, а $\mathcal{T}_{-\delta}$ — обратный сдвиг для компенсации смещения изображения.
    
    \item \textbf{Center Drift (CD)}: измеряет среднее смещение центров предсказанных ограничивающих рамок при сдвигах:
    \begin{equation}
    \text{CD} = \mathbb{E}_{x, \delta, b} [||\text{center}(b) - \text{center}(\mathcal{T}_{-\delta}(b_{\delta}))||_2]
    \end{equation}
    
    \item \textbf{Classification Stability (CS)}: оценивает стабильность классификации обнаруженных объектов:
    \begin{equation}
    \text{CS} = \mathbb{E}_{x, \delta, b} [\text{cos\_sim}(c(b), c(b_{\delta}))]
    \end{equation}
    где $c(b)$ — вектор вероятностей классификации для ограничивающей рамки $b$.
\end{itemize}

\subsubsection{Протокол тестирования}
\label{sec:evaluation:protocol}

Для обеспечения строгости и воспроизводимости результатов используется следующий протокол тестирования:

\begin{enumerate}
    \item \textbf{Генерация сдвигов}: Для каждого тестового изображения создается набор сдвинутых версий. Сдвиги выполняются с высокой точностью (до 1/8 пикселя) в диапазоне $[-8, 8]$ пикселей по обеим осям. Интерполяция выполняется с помощью бикубического метода для минимизации артефактов ресемплинга.
    
    \item \textbf{Предобработка}: Все изображения стандартизируются к размеру 224×224 пикселей для классификационных моделей и 640×640 пикселей для моделей детекции. Применяется стандартная нормализация, но без аугментации данных.
    
    \item \textbf{Проверка инвариантности}: Каждое изображение (оригинальное и сдвинутые версии) пропускается через модель, и фиксируются соответствующие выходные данные. Для каждой пары (оригинал, сдвинутая версия) вычисляются метрики инвариантности.
    
    \item \textbf{Агрегация результатов}: Метрики усредняются по всем тестовым изображениям и всем рассмотренным сдвигам для получения итоговых показателей.
\end{enumerate}

Такой подход позволяет провести исчерпывающую оценку инвариантности моделей и сравнить эффективность различных методов анти-алиасинга в задачах классификации и детекции объектов.

\newpage
